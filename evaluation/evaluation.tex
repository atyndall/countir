\documentclass[../thesis/thesis.tex]{subfiles}
\begin{document}
 \chapter{Evaluation}

\section{Sensor Properties}

In order to best utilize the \mlx, we must first understand the properties it exhibits, and their potential affects on our ability to perform person related measurements. These properties can be broadly separated into three different categories; bias, noise and sensitivity. A broad range of data was collected with the sensor in a horizontal orientation using various sources of heat and cold to determine these properties. This experimental setup is described in \Fref{fig:exps:2setup}.

\begin{figure}
\centering
\includegraphics[height=0.9\textheight]{../diagrams/second-exp-setup2.pdf}
\caption{Experiment setup to determine sensor properties}
\label{fig:exps:2setup}
\end{figure}


\subsection{Bias}
When receiving no infrared radiation, the sensor should indicate a near-zero temperature. If in such conditions it does not, that indicates that the sensor has some level of bias in its measurement values. We attempted to investigate this bias by performing thermal captures of the night sky. While this does not completely remove the infrared radiation, it does remove a significant proportion of it.

In \Fref{fig:meanstdplot} the thermal sensor was exposed to the night sky at a capture rate of 1Hz for 4 minutes, with the sensing results combined to create a set of means and standard deviations to indicate the pixels at ``rest''. The average temperature detected was $11.78\dc$, with the standard deviation remaining less than $0.51\dc$ over the entire exposure period. The resultant thermal map shows that pixels centered around the four ``primary'' pixels in the center maintain a similar temperature around $9\dc$, with temperatures beginning to deviate as they became further from the center.

The most likely cause of this bias is related to the physical structure of the sensor. The \mlx is a rectangular sensor which has been placed inside a circular tube. Due to this physical arrangement, the sides of this rectangular sensor will be significantly closer to these edges than the center. If these sides are at an ambient temperature higher than the measurement data (as they were in this case) thermal radiation from the sensor package itself could provide significant enough to cause the edges to appear warmer than the observed area of the sky. Such issues with temperature could be controlled for using a device that cools the sensor package to below that of the ambient temperature being measured, however, this is not a concern in this project, as the method of calculating a thermal background will compensate for any such bias as long as it remains constant.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../diagrams/rest-avg.pdf}
\includegraphics[width=\textwidth]{../diagrams/rest-stddev.pdf}
\caption{Plot of pixel means (top) and standard deviations (bottom) at rest}
\label{fig:meanstdplot}
\end{figure}


\subsection{Noise}

One of the features of the \mlx is the ability to sample the thermal data and a variety of sample rates between 0.5Hz and 512Hz. However, it was noted in early experimentation that a higher sample rate resulted in an increase in the noise contained within the resultant images. As our experiments focus on separating objects of interest from a thermal background, it is important to determine the maximum level of noise tolerable before our algorithms are unable to separate the background from the objects of interest.

\Fref{fig:noise} plots one of the central pixels of the sensor in a scenario where it is merely viewing a background (shown in green), and when it is viewing a person (shown in red), at the 5 different sample rates achievable with the current hardware. We can see in these plots that the data becomes significantly more noisy as the sample rate increases, and we can also determine that the sensor uses a form of data smoothing at lower sample rates, as the variance in data increases with sample rate.

If the sample rate were to increase, it is likely that the ability for the sensing system to disambiguate between objects of interest and the background would diminish. However, in the current project, even the slowest sampling rate of 0.5Hz is sufficient, as occupancy estimations at a sub-second level present little additional value and would require significant reforms in the efficiency of the software used.

% TODO: Signal to noise ratio calculations

\begin{figure}
  \centering
  \input{../data/processed/noise-graph/good} % TODO: Label lines
\caption{Noise levels of occupants (higher) and background (lower) at various sampling speeds}
\label{fig:noise}
\end{figure}


\subsection{Sensitivity}

The \mlx is a sensor composed of 64 independent non-contact digital thermopiles, which measure infrared radiation to determine the temperature of objects. While they are bundled in one package, \Fref{fig:exps:blockdia} shows that they are in fact wholly independent sensors placed in a grid structure. This has important effects on the properties of the data that the \mlx produces. 

\Fref{fig:hotmotion} shows a graph of the temperatures of the top row of 16 pixels of the \mlx as a hot object is moved from left to right at an approximately similar speed. One of the most interesting phenomena in this graph is the apparent extreme variability of the detected temperature of the object as it moves ``between'' two different pixels; there is a noticeable drop in the objects detected temperature. Further analysis of each of the pixel's lines on the graph shows each pixel exhibiting a bell-curve like structure, with the detected temperature increasing from the baseline and peaking as the object enters the center of the pixel, and the detected temperature similarly decreasing as the object leaves the center. 

This phenomenon has several possible causes. One likely explanation is that each individual pixel detects objects radiating at less favorable angles of incidence to be colder than they actually are: As the object enters a pixel's effective field of view, it will radiate into the pixel at an angle that is at the edge of the pixel's ability to sense, with this angle slowing decreasing until the hot object is directly radiating into the pixel's sensor, causing a peak in the temperature reading. As the object leaves the individual elements field of view, the same happens in reverse.

While interesting, this phenomenon has little consequence to the effectiveness of the techniques used, as in experimental conditions the sensor will not be sufficiently distant that humans could be detected as single pixels. However, this phenomenon could be leveraged in future work to perform sub-pixel localization, discussed later on.


\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{../diagrams/mlx-block-diagram.pdf}
\caption{Block diagram for the \mlx taken from datasheet \cite{MLXDatasheet}}
\label{fig:exps:blockdia}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../diagrams/temp/motion.pdf}
\caption{Different \mlx pixel temperature values as hot object moves across row}
\label{fig:hotmotion}
\end{figure}

\section{Energy Efficiency}

TODO: This section will contain experimental descriptions relating to the power consumption of the prototype.

\section{Classification Accuracy}

With the prototype, it is now possible to utilize the prototype to gather both thermal and visual data in a synchronized format. This data can be collected and used to determine the effectiveness of the human counting algorithms used. Due to the prototype's technical similarly to Thermosense \cite{beltran2013thermosense}, a similar set of experimental conditions will be used, with a comparison against Thermosense being used as a benchmark. To this end, several experiments were devised, each of which had its data gathered and processed in accordance with the same general process, outlined in \Fref{fig:methods:flowchart}.

\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{../diagrams/temp/method-flowchart.pdf}
\caption{Flowchart of processing}
\label{fig:methods:flowchart}
\end{figure}

\subsection{Data gathering}
As the camera and the Arduino are directly plugged into the Raspberry Pi, all data capture is performed on-board through SSH, with the data being then copied of the Pi for later processing. To perform this capture, the main script used is \texttt{capture\_pi\_synced.py}.

\texttt{capture\_pi\_synced.py} takes two parameters on the command line; the name of the capture output, and the number of seconds to capture. By default, it always captures at 2Hz. The script initializes the \texttt{picamera} library, then passes a reference to it to the \texttt{capture\_synced} function within the \texttt{Visualizer} class. The class will then handle the sending of commands to the Arduino to capture data in concert with taking still frames with the Raspberry Pi's camera.

When the script runs, it creates a folder with the name specified, storing inside a file named \texttt{output\_thermal.hcap} containing the thermal capture, and a sequence of files with the format \texttt{video-\%09d.jpg}, corresponding to each visual capture frame.

\subsection{Data labeling}
Once this data capture is complete, the data is copied to a more powerful computer for labeling. The utility \texttt{tagging.py} is used for this stage. This script is passed the path to the capture directory, and the number of frames at the beginning of the capture that are guaranteed to contain no motion. This utility will display frame by frame each visual and thermal capture together, as well as the computed feature vectors (based on a background map created from the first $n$ frames without motion).

The user is then required to press one of the number keys on their keyboard to indicate the number of people present in this frame. This number will be recorded in a file called \texttt{truth} in the capture directory. The next frame will then be displayed, and the process continues. This utility enables the quick input of the ground truth of each capture, making the process more efficient.

\subsection{Feature extraction and data conversion}
% TODO: Explain classification

Once the ground truth data is available, it is now possible to utilize the data to perform various classification tests. For this, we use version 3.7.12 of the open-source Weka toolkit \cite{Weka}, which provides easy access to a variety of machine learning algorithms and the tools necessary to analyze their effectiveness.

To enable the use of Weka, we export the ground truth and extracted features to a Comma Seperated Value (CSV) file for processing. \texttt{weka\_export.py} takes two parameters, a comma-separated list of different experiment directories to pull ground truth and feature data from, and the number of frames at the beginning of each capture that can be considered as ``motionless.'' With this information, a CSV-file file is generated on which the heading indicating the attribute names is added for Weka to recognize.

\subsection{Running Weka Tests}
Once the CSV file is generated, it is then possible to open the file in Weka for processing. Weka provides a variety of algorithms, but we choose a specific subset of algorithms based on those present in the Thermosense paper \cite{beltran2013thermosense}, as well others that we believe adequately represent the different approaches to classification.


\begin{landscape}
\begin{table}
\centering
\begin{tabular}{|p{50mm}|p{20mm}|p{125mm}|}
\hline
\textbf{Type} & \textbf{Attribute} & \textbf{Weka Class} \& \textbf{Parameters} \\ \hline

Neural Network (ANN) & {Nominal, \newline Numeric} & \texttt{weka.classifiers.functions.MultilayerPerceptron \newline -L 0.3 -M 0.2 -N 500 -V 15 -S 0 -E 20 -H 5} \\ \hline

$k$-nearest Neighbors (KNN) & Nominal, \newline Numeric & \texttt{weka.classifiers.lazy.IBk \newline -K 5 -W 0 -F \newline -A "weka.core.neighboursearch.LinearNNSearch -A \textbackslash"weka.core.EuclideanDistance -R first-last\textbackslash""} \\ \hline

Naive Bayes & Nominal & \texttt{weka.classifiers.bayes.NaiveBayes} \\ \hline

Support Vector Machine (SVM) & Nominal & \texttt{weka.classifiers.functions.SMO \newline -C 1.0 -L 0.001 -P 1.0E-12 -N 0 -V -1 -W 1 \newline -K "weka.classifiers.functions.supportVector.PolyKernel -C 250007 -E 1.0"} \\ \hline

Decision Tree & Nominal & \texttt{weka.classifiers.trees.J48 \newline -C 0.25 -M 2} \\ \hline

Entropy Distance & Nominal, \newline Numeric & \texttt{weka.classifiers.lazy.KStar \newline -B 20 -M a} \\ \hline % TODO: Check that entropy distance

Linear Regression & Numeric & \texttt{weka.classifiers.functions.LinearRegression \newline -S 0 -R 1.0E-8} \\ \hline

0-R & Nominal, \newline Numeric & \texttt{weka.classifiers.rules.ZeroR} \\ \hline
\end{tabular}
\caption{Weka parameters used for classifications}
\label{tab:methods:params}
\end{table}
\end{landscape}

For those tests that are ``nominal,'' the \texttt{npeople} attribute was interpreted as nominal using the ``NumericToNominal'' filter, which creates a class for each value deleted in \texttt{npeople}'s columns. For those tests that are ``numeric,'' \texttt{npeople} is left unchanged, as by default all CSV import attributes are interpreted as such. For all tests where not specifically instructed, we use 10-fold cross-validation to validate our results.

As the data we are using is based on real experiments, the number of frames which are classified as each class may be unbalanced, which could cause the classification results to be affected. To that end, for each classification technique, we both classify the data in its raw, unbalanced form, and we also uniformly re-sample the \texttt{npeople} parameter using \texttt{weka.filters.supervised.instance.Resample -B 1.0 -S 1 -Z 100.0} in the pre-processing stage.

To help maximize the efficiency of the classification task, we use the Weka Knowledge Flow constructor to generate an encompassing flow that accepts an input CSV file of the raw data, and performs all resampling, numeric and nominal classification, returning a text file with the results of each of the different classification techniques run. The knowledge flow's struture can be seen in \label{fig:methods:unifiedflow}. To enable maximum efficiency, the input and output elements of this flow are set to the environmental variables \texttt{UnifiedFlow.InputCSV} and \texttt{UnifiedFlow.OutputCSV}, a Jython script, \texttt{run\_flow.py}, then sets those environmental variables to input and output file names, then calls the flow using Weka's Java API. After this is complete, the script then runs a series of regexes on the output text data to generate summary spreadsheets with the relevant values.

\begin{landscape}
\begin{figure}
\centering
\includegraphics[width=0.95\linewidth]{../diagrams/unified-flow.png}
\caption{Unified Knowledge Flow for all experiments}
\label{fig:methods:unifiedflow}
\end{figure}
\end{landscape}


\subsection{Classifier Experiment Set 1}
In our first set of experiments, a scene was devised in accordance with \Fref{fig:exps:3setup} that attempted to sense people from above, as did Thermosense. The prototype was set up on the ceiling, pointing down at a slight angle. For ease of use, the prototype was powered by mains power, and was networked with a laptop for command input and data collection via Ethernet. This set of experiments involved between zero and three people being present in the scene, moving in and out in various ways in accordance with the script in \Fref{tab:exps:3script}.

\begin{table}
\centering
\begin{enumerate}
\item (Remained standing) One person walks in, stands in center, walks out of frame. (sub-experiment 1)
\item (Remained standing) One person walks in, joined by another person, both stand there, one leaves, then another leaves. (sub-experiment 2)
\item (Remained standing) One person walks in, joined by one, joined by another, all stand there, one leaves, then another, then another. (sub-experiment 3)
\item (Remained standing) Two people walk in simultaneously, both stand there, both leave simultaneously. (sub-experiment 4)
\item (Sitting) One person walks in, sits in center, moves to right, walks out of frame. (sub-experiment 5)
\item (Sitting) One person walks in, joined by another person, both sit there, they stand and switch chairs, one leaves, then another leaves. (sub-experiment 6)
\item (Sitting) One person walks in, joined by one, joined by another, they all sit there, one leaves, one shuffles position, then another leaves, then another. (x2) (sub-experiment 7, 8)
\item (Sitting) Two people walk in, both sit there, both leave. (sub-experiment 9)
\end{enumerate}
\caption{Experiment Set 1 Script}
\label{tab:exps:3script}
\end{table}

\begin{landscape}
 \begin{figure}
 \centering
 \includegraphics[height=\textheight]{../diagrams/third-exp-setup2.pdf}
 \caption{Classifier Experiment Set 1 Setup}
 \label{fig:exps:3setup}
 \end{figure}
\end{landscape}

In these experiments people moved slowly and deliberately, making sure there were large pauses between changes of action. The people involved were of average height, wearing various clothing. The room was cooled to 18 degrees for these experiments.

Each experiment was recorded with a thermal-visual synchronization at 1Hz over approximately 60-120 second intervals. Each experiment had 10-15 frames at the beginning where nothing was within the view of the sensor to allow the thermal background to be calculated. Each frame generated from these experiments was manually tagged with the ground truth value of its occupancy using the script mentioned previously.

The resulting features and ground truth were combined and exported to CSV allowing the Weka machine learning program to analyze them. This data was analyzed with the feature vectors always being considered numeric data and with the ground truth considered both numeric and nominal. All previously mentioned classification algorithms were run against the data set.

% TODO: Outline J48 decision tree

\begin{table}
\centering
\begin{tabular}{|l|r|r|r|r|r|r|}
\hline
\textbf{Classifier} & \multicolumn{2}{c|}{\textbf{RMSE}}                                            & \multicolumn{2}{c|}{\textbf{\%}}                                              & \multicolumn{2}{c|}{\textbf{$R^2$}}                                           \\ \hline
                    & \multicolumn{1}{l|}{\textbf{Excl. 0}} & \multicolumn{1}{l|}{\textbf{Incl. 0}} & \multicolumn{1}{l|}{\textbf{Excl. 0}} & \multicolumn{1}{l|}{\textbf{Incl. 0}} & \multicolumn{1}{l|}{\textbf{Excl. 0}} & \multicolumn{1}{l|}{\textbf{Incl. 0}} \\ \hline
\multicolumn{7}{|c|}{Thermosense Replication} \\ \hline                                                                                                                                                                                                                       
KNN (Nominal)       & -                                     & 0.364        & -           & 65.65         & -           & -                                     \\ \hline
KNN (Numeric)       & -                                     & 1.1235       & -           & -             & -           & 0.3766                                \\ \hline
MLP                 & 0.592                                 & -            & -           & -             & 0.687       & -                                     \\ \hline
Lin Reg             & 0.525                                 & -            & -           & -             & 0.589       & -                                     \\ \hline
\multicolumn{7}{|c|}{Nominal Balanced}                                                                                                                         \\ \hline
C4.5                & 0.289                                 & 0.290        & 84.96       & 77.56         & -           & -                                     \\ \hline
K*                  & 0.296                                 & 0.293        & 84.27       & 78.25         & -           & -                                     \\ \hline
MLP                 & 0.359                                 & 0.320        & 70.86       & 72.13         & -           & -                                     \\ \hline
Bayes               & 0.409                                 & 0.368        & 63.76       & 61.52         & -           & -                                     \\ \hline
SVM                 & 0.410                                 & 0.386        & 65.98       & 56.89         & -           & -                                     \\ \hline
0-R                 & 0.471                                 & 0.433        & 32.48       & 24.61         & -           & -                                     \\ \hline
\multicolumn{7}{|c|}{Numeric}                                                                                                                                  \\ \hline
K*                  & 0.423                                 & 0.550        & -           & -             & 0.760       & 0.828                                 \\ \hline
0-R                 & 0.651                                 & 0.972        & -           & -             & -0.118      & -0.129                                \\ \hline
\multicolumn{7}{|c|}{Nominal Unbalanced}                                                                                                                       \\ \hline
C4.5                & 0.314                                 & 0.288        & 82.39       & 82.91         & -           & -                                     \\ \hline
K*                  & 0.304                                 & 0.285        & 82.56       & 82.61         & -           & -                                     \\ \hline
MLP                 & 0.362                                 & 0.286        & 77.14       & 78.69         & -           & -                                     \\ \hline
Bayes               & 0.405                                 & 0.352        & 63.59       & 66.21         & -           & -                                     \\ \hline
SVM                 & 0.398                                 & 0.380        & 67.18       & 57.47         & -           & -                                     \\ \hline
0-R                 & 0.442                                 & 0.415        & 49.74       & 40.37         & -           & -                                     \\ \hline
\end{tabular}
\caption{Classifier Experiment Set 1 Results}
\label{tab:results:set1}
\end{table}

Experimental results from the first set of experiments were overall excellent, results from them can be seen in \Fref{tab:results:set1}. In the unbalanced results when including zero, an accuracy of 82.9\% was observed, and in the balanced results, 78.2\%.  When excluding zero, the unbalanced results achieved 82.5\% in the unbalanced and up to 84.9\% in the balanced results.

\begin{figure}
\centering
\includegraphics{../diagrams/temp/resample.png}
\caption{Experiment Set 1 Class Distribution Before and After Weka Re-sampling}
\label{fig:results:resample}
\end{figure}

Between the unbalanced and balanced classes when including zero, the ranking of different algorithms remained approximately the same, and consistently dropped in accuracy, with the exceptions being the SVM technique, which increased in accuracy by about 1\% in that instance. The drop in accuracy can be explained mostly by an over-representation of the zero class within the under-balanced data, as well as an underrepresentation of the three class (see \Fref{fig:results:resample}). This is conformed by the fact that in the zero-excluded data, there is much less difference in the balanced and unbalanced set. These biases would enable classes to over-predict and under-predict these two classes respectively and achieve an artificially higher accuracy as a result. As discussed in the Methods, we performed re-sampling inside Weka to compensate for this.

For the numeric representation of the number of people, accuracy was consistently poor. From this data, we can see that all three classifiers used performed consistently poorly, with the Root Mean Square Errors being consistently double or more of comparable nominal results, and with correlation coefficients ($R^2$) indicating poor (or in the case of KNN) very poor correlations.

The two highest accuracy classifiers, C4.5 and K*, achieved quite similar results for both the balanced and unbalanced data while being quite different in implementation. % TODO: Why is this the case

TODO: Discuss and compare this to ZeroR's RMSE. It's RMSE is quite close to some results, is this bad?

\subsubsection{Individual sub-experiment results}

In addition to the above aggregate classification results, in which each of the nine sub-experiments results are combined and fed into the classifier, each of the sub-experiments has been individually classified with each of the six balanced nominal classifiers above. The results for these classifications can be seen in \Fref{tab:results:set1percent} and \Fref{tab:results:set1rmse}.

TODO: We talk about points of interest in the sub-experiment results and see if we can draw any useful conclusions from them.


\begin{landscape}
\begin{table}
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
\hline
        & \textbf{1}     & \textbf{2}     & \textbf{3}     & \textbf{4}     & \textbf{5}     & \textbf{6}     & \textbf{7}     & \textbf{8}     & \textbf{9}     & \textbf{Avg}   \\ \hline
\multicolumn{11}{|c|}{Nominal}                                                                                                                                                    \\ \hline
KNN     & 0.584          & 0.422          & 0.375          & 0.425          & 0.651          & 0.352          & 0.396          & 0.338          & 0.244          & \textit{0.421} \\ \hline
C4.5    & 0.342          & 0.270          & 0.278          & 0.414          & 0.456          & 0.267          & 0.318          & 0.288          & 0.250          & \textit{0.320} \\ \hline
K*      & 0.305          & 0.249          & 0.260          & 0.412          & 0.407          & 0.245          & 0.299          & 0.265          & 0.196          & \textit{0.293} \\ \hline
MLP     & 0.345          & 0.275          & 0.272          & 0.399          & 0.466          & 0.232          & 0.389          & 0.246          & 0.242          & \textit{0.318} \\ \hline
Bayes   & 0.391          & 0.359          & 0.290          & 0.435          & 0.473          & 0.276          & 0.381          & 0.306          & 0.243          & \textit{0.351} \\ \hline
SVM     & 0.447          & 0.447          & 0.379          & 0.444          & 0.602          & 0.378          & 0.380          & 0.377          & 0.335          & \textit{0.421} \\ \hline
\multicolumn{11}{|c|}{Numeric}                                                                                                                                                    \\ \hline
0-R     & 0.500          & 0.471          & 0.433          & 0.472          & 0.500          & 0.471          & 0.433          & 0.433          & 0.472          & \textit{0.465} \\ \hline
KNN     & 0.726          & 0.707          & 1.044          & 0.934          & 0.593          & 0.531          & 0.899          & 0.585          & 0.829          & \textit{0.761} \\ \hline
K*      & 0.256          & 0.422          & 0.598          & 0.806          & 0.377          & 0.432          & 0.586          & 0.627          & 0.472          & \textit{0.508} \\ \hline
Lin Reg & 0.270          & 0.635          & 0.623          & 0.821          & 0.422          & 0.508          & 0.589          & 0.708          & 0.570          & \textit{0.572} \\ \hline
MLP     & 0.379          & 0.460          & 0.500          & 0.868          & 0.399          & 0.306          & 0.790          & 0.490          & 0.406          & \textit{0.511} \\ \hline
0-R     & 0.409          & 0.762          & 1.009          & 0.986          & 0.507          & 0.829          & 1.014          & 1.043          & 1.012          & \textit{0.841} \\ \hline
Avg     & \textit{0.413} & \textit{0.457} & \textit{0.505} & \textit{0.618} & \textit{0.488} & \textit{0.402} & \textit{0.539} & \textit{0.475} & \textit{0.439} &                \\ \hline
\end{tabular}
\caption{Classifier Experiment Set 1 Individual Sub-experiment RMSEs}
\label{tab:results:set1rmse}
\end{table}
\end{landscape}

\section{Thermosense Comparison and Discussion}

To aid in comparison with the Thermosense algorithm, in our experiment sets we chose three techniques similar to those used in Thermosense; an Artificial Neural Network (Multilayer Perceptron in Weka), $k$-nearest Neighbors (IBk in Weka) and Linear Regression. Our results for our approximations to their algorithms can be seen in the Thermosense Replication section of \Fref{tab:results:set1}. We also use an experimental setup with 0--3 or 1--3 people, depending on the classifier, just as the Thermosense experiments do. For KNN, it was ambiguous if Thermosense used numeric or a nominal class attributes in their experiments, so we have performed both options above. The specifics of this is discussed in the Methods chapter.

For those experiments where we tried to specifically replicate Thermosense' results, we found consistently poor results that did not come close to meeting the $R^2$ or RMSE values that Thermosense claimed. Their $R^2$ values were in the 0.8 range, while ours range from around 0.3--0.7. This can be put down to a multitude of factors, with one likely explanation being that differences with the \mlx's narrower field of view being difficult for Thermosense' specific algorithmic selections to deal with.

Our Linear Regression (\Fref{eq:linreg}) underperforms particularly when compared to Thermosense' (\Fref{eq:thermolinreg}), as it fails to find an adequate way to weight the two variables, instead opting to basically exclude them from consideration by picking very small weights and adding a large constant factor. We get a correlation of $R^2 = 0.589$ vs Thermosense' $R^2 = 0.858$.

\begin{equation} \label{eq:linreg}
n =  0.0456a + -0.024s + 1.1772
\end{equation}

\begin{equation} \label{eq:thermolinreg}
n =  0.141a + -0.051s + 0.201
\end{equation}

However, for those algorithms we chose ourselves to test, we found results that were comparable or even better than Thermosense. Our nominally classed C4.5 decision tree achieved an balanced RMSE excluding zero of 0.289, compared to Thermosense' best result of 0.346. In the numeric classes, the K* implementation achieved correlations in the same ballpark of 0.760 (excl. 0) and 0.828 (incl. 0), compared to Thermosense' best 0.906 for their ANN.

However, none of the techniques used by Thermosense proved to be the best out of those algorithms tried. The Neural Network and $k$-nearest Neighbors techniques represent the middle-of-the-road of our results, with both being bested by the C4.5 and K* algorithms, which produced RMSEs of 0.289 and 0.298 respectively. Both these results are significantly better than Thermosense's best RMSE of 0.346 for $k$-nearest Neighbors, with our C4.5 algorithm representing a 28\% improvement over that technique.


  \ifcsdef{mainfile}{}{\bibliography{../references/primary}}
\end{document}
 