\documentclass[../thesis/thesis.tex]{subfiles}
\begin{document}
 \chapter{Design and Implementation}
 \label{chap:design}

To investigate thermal sensing's potential, a software and hardware prototype (the ``sensing system'') must now be constructed to provide a platform for experimentation and evaluation of the sensor chosen, as well as to capture, store, visualize and replay sensor data for those purposes. We will first discuss the hardware foundations of the project, then the architecture of the software developed to run on those foundations.

\section{Hardware}

As reliability and future extensibility are core concerns of the project, a three-tiered system is employed with regards to the hardware involved in the system (\Fref{tab:sensor:tiers}). At the bottom, the Sensing Tier, we have the sensors themselves. Connected to the sensors via those respective protocols is the Preprocessing Tier, hosted on an embedded system. The embedded device polls the data from these sensors, performs necessary calculations to turn the raw sensor information into actionable data, and communicates this via Serial over USB to the third tier. The third tier, the Analysis Tier, is run on a fully fledged computer. In our prototype, it captures and stores temperature and motion data it receives over Serial over USB, as well as visual data for ground truth purposes.

In the current prototype, the Analysis Tier merely stores captured data for offline analysis, in future prototypes this analysis can be done live and served to interested parties over a RESTful API. In the current prototype, the Analysis and Sensing Tiers are connected by Serial over USB, in future prototypes, this can be replaced by a wireless mesh network, with many Preprocessing/Sensing Tier nodes communicating with one Analysis Tier node.

\begin{table}
\centering
\begin{tabular}{|r|l|}
\hline
\textbf{Analysis Tier} & Raspberry Pi B+ \\ \hline
\textbf{Preprocessing Tier} & \ard Uno R3 \\ \hline
\textbf{Sensing Tier} & \acl{mlx} \& PIR \\ \hline
\end{tabular}
\caption{Three-tier structure of prototype hardware with corresponding components used}
\label{tab:sensor:tiers}
\end{table}

\subsection{Sensing}
As discussed in the Literature Review, using a \iar appear to be the most viable way to achieve the high-level goals of this project. ThermoSense~\cite{beltran2013thermosense}, the primary occupancy sensor in the \iar space, used the low-cost Panasonic \geye sensor for this task. This sensor, costing around \$50, was suggested by ThermoSense to be effective in occupancy detection. However, while still available for sale in the United States, we were unable to order the sensor for shipping to Australia due to supplier-vendor contract agreements outside of our control. Using a sensor with such restrictions in place goes against an implicit criteria of the parts used in the project being relatively easy to acquire.

This forced us to search for alternative sensors in the space that fulfill similar criteria but were available in Australia. The sensor we chose was the \mlx~\cite{MLXDatasheet}, a \iar with similar overall qualities that differed in several important ways; it provides a $16 \times 4$ grid of thermal information, it has an overall narrower field of view and it sells for approximately \$80. Like the \geye, the \mlx communicates over the 2-wire \iic bus, a low-level bi-directional communication bus widely used and supported in embedded systems.

We envision a further advanced prototype to have wireless networking in a smaller form factor, much like ThermoSense. However, due to time and resource constraints, the scope of this project has been limited to a minimum viable implementation. This prototype architecture has been designed such that a clear path to an idea system architecture involving each Pre-Processing Tier and Analysis Tier being connected by a wireless mesh network to enable easy installation in households.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../diagrams/mlx-arduino2.pdf}
\caption{MLX90620, Passive Infrared Sensor, and Arduino integration circuit diagram}
\label{fig:circuits:node}
\end{figure}

\subsection{Pre-Processing}

Due to low cost, broad support and ease of development, the \ard platform was selected as the host for the Preprocessing Tier, and thus will handle the \iic communication with the \mlx. Initially, this presented some challenges, as the \mlx recommends a power and communication voltage of 2.6V, while the \ard is only able to output 3.3V and 5V as power, and 5V as communication. Due to this, it was not possible to directly connect the \ard to the \mlx, and similarly due to the two-way nature of the \iic 2-wire communication protocol, it was also not possible to simply lower the \ard voltage using simple electrical techniques, as such techniques would interfere with two-way communication.

A solution was found in the form of a \iic level-shifter, the Adafruit ``4-channel I2C-safe Bi-directional Logic Level Converter''~\cite{AdafruitI2C}, which provided a cheap method to bi-directionally communicate between the two devices at their own preferred voltages. The layout of the circuit necessary to link the \ard and the \mlx, including the use of this converter, can be seen in \Fref{fig:circuits:node}.

Additionally, as used in the ThermoSense paper, a \pir motion detector~\cite{AdafruitPIR} was also connected to the \ard. This sensor, operating at 5V natively, did not require any complex circuitry to interface with the \ard. It is connected to digital pin 2 on the \ard, where it provides a rising signal (a ``trigger'') in the event that motion is detected, which can be configured to cause an interrupt on the \ard. In the configuration used in this project, the sensor's sensitivity was set to the highest value and the timeout for re-triggering (the trigger reoccurring) was set to the lowest value (approximately 2.5 seconds). Additionally, the continuous re-triggering feature (whereby the sensor produces continuous rising and falling signals for the duration of motion) was disabled using the provided jumpers. 

\subsection{Analysis / Classification}
For the Analysis Tier, the Raspberry Pi B+ was chosen, as it is a powerful and inexpensive computer capable of running Linux. The \ard is connected to the Raspberry Pi over USB, which provides it both power and the capacity to transfer data. In turn, the Raspberry Pi is connected to a simple micro-USB rechargeable battery pack, which provides it with power, and subsequently the \ard and sensors.

\subsection{Component Costs}
\label{subsec:cost}

As being low-cost is one of the project's goals, we have summarized the cost of each of the components of the prototype in \Fref{tab:sensor:cost}. We believe that for a prototype, this cost is sufficiently low. In the envisioned system, there would only be one Raspberry Pi in the system, and it would not require a camera, lowering the cost to around $\$50 + \$135n$ where $n$ is the number of sensors. Similarly, as technology improves, sensor technology expected to continue to fall in price, causing the most expensive component, the infra-red sensor, to become increasingly cost-effective.

When we compare this to the estimated cost of the ThermoSense system (\Fref{tab:sensor:thermosensecost}), we believe that it achieves a suitably comparable cost for a prototype. When removing the aspects of the prototype that would be unnecessary in the final version, the difference is only \$15.

\begin{table}[b]
\centering
\begin{subtable}[b]{0.5\textwidth}
\centering
\begin{tabular}{|l|r|}
\hline
\textbf{Part} & \textbf{Cost} \\ \hline
MLX90620 & \$80 \\ \hline
Raspberry Pi B+ &  \$50 \\ \hline
Arduino Uno R3 & \$40 \\ \hline
Passive Infrared Sensor & \$10 \\ \hline
\iic level shifter & \$5 \\ \hline
\textbf{TOTAL} & \textbf{\$185} \\ \hline
\end{tabular}
\caption{Our project}
\label{tab:sensor:cost}
\end{subtable}%
~%
\begin{subtable}[b]{0.5\textwidth}
\centering
\begin{tabular}{|l|r|}
\hline
\textbf{Part} & \textbf{Cost} \\ \hline
TMote Sky & \$110 \\ \hline
Grid-EYE & \$50 \\ \hline
Passive Infrared Sensor & \$10 \\ \hline
 & \\ \hline
 & \\ \hline
\textbf{TOTAL} & \textbf{\$170} \\ \hline
\end{tabular}
\caption{ThermoSense (estimated)}
\label{tab:sensor:thermosensecost}
\end{subtable}
\caption{Breakdown of component costs for minimum viable implementation}
\end{table}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../diagrams/prototypeb-1.jpg}
\includegraphics[width=\textwidth]{../diagrams/prototypeb-2.jpg}
{\footnotesize
\begin{multicols}{3}
\begin{enumerate}[a)]
 \item Battery pack
 \item Raspberry Pi
 \item Arduino
 \item Level-shifting circuitry
 \item Movable sensor mount
 \item PIR
 \item Camera
 \item MLX90620
\end{enumerate}
\end{multicols}
}
\caption{Component breakdown of sensing system prototype}
\label{fig:pictures:protob1}
\end{figure}

\begin{figure}
\centering
\includegraphics[height=0.7\textheight]{../diagrams/prototype-mounted-ceiling.jpg}
\begin{enumerate}[a)]
 \item Sensors (refer to \Fref{fig:pictures:protob1})
 \item Mounting pole
\end{enumerate}
\caption{Sensing system prototype mounted on roof}
\label{fig:pictures:protoact}
\end{figure}

\clearpage{}

\section{Software}

\begin{table}
\centering
\begin{subtable}[b]{0.5\textwidth}
\centering
\begin{tabular}{|l|r|}
\hline
\textbf{Category} & \textbf{SLOC}  \\ \hline
TArL Python       & 674            \\ \hline
\hspace{5mm}\texttt{cam}        & 425           \\ \hline
\hspace{5mm}\texttt{features}   & 191           \\ \hline
\hspace{5mm}\texttt{pxdisplay}  & 58            \\ \hline
TArL Arduino  & 492            \\ \hline
\hspace{5mm}\texttt{mlx90620\_driver}  & 492          \\ \hline
Analysis Scripts  & 147            \\ \hline
Capture Scripts   & 234            \\ \hline
\textit{Total}    & \textit{1,624} \\ \hline
\end{tabular}
\caption{Source Lines Of Code written}
\end{subtable}%
~%
\begin{subtable}[b]{0.5\textwidth}
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Library}     & \multicolumn{1}{l|}{\textbf{Version}} \\ \hline
\multicolumn{2}{|c|}{Arduino}                                \\ \hline
SDK                  & 1.6.4                                 \\ \hline
\texttt{SimpleTimer} & 1.0                                   \\ \hline
\multicolumn{2}{|c|}{Python}                                 \\ \hline
\texttt{networkx}    & 1.9.1                                 \\ \hline
\texttt{numpy}       & 1.8.0                                 \\ \hline
\texttt{matplotlib}  & 1.3.1                                 \\ \hline
\texttt{picamera}    & 1.10                                  \\ \hline
\texttt{Pillow}      & 2.8.1                                 \\ \hline
\end{tabular}
\caption{Libraries used}
\end{subtable}
\caption{Summary of code written and used within the Thermal Array Library}
\end{table}

\begin{figure}
\centering
\input{../diagrams/prototype-system}
\caption{Architecture of prototype sensor with tiers, software, communication protocols and information flow}
\label{fig:pictures:protob-arch}
\end{figure}

At each layer of the described three-tier software architecture (pictured in greater detail in \Fref{fig:pictures:protob-arch}), software exists to govern the operation of that tier's functionality. For the sensing tier, the \mlx and \pir's own software is used, while for the other tiers, a bi-lingual software library, \tarl, was developed to provide a suite of functions to enable the easy data collection and analysis of information from the hardware prototype. \tarl is split into two parts:

At the Preprocessing Tier, the Arduino, the \tarl \mlx driver is found, which is written in the default Arduino C++ derivative language. The used of a low-level language is important at this tier as careful management of memory usage and algorithmic complexity is required in such a resource-constrained environment.

At Analysis Tier, a general purpose computer is used, and that is where the bulk of \tarl can be found. As the processing environment has become less constrained, the choice of language becomes a possibility. In this instance, Python was chosen as \tarl's language on the Analysis Tier. Python was chosen as it is a high-level language with excellent library support for the functions required of the Analysis Tier, including serial interface, the use of the Raspberry Pi's built in camera, and image analysis. The 2.x branch of Python was chosen over the 3.x branch, despite its age, due a greater maturity in support for several key graphical interface libraries. Much of the Analysis tier's code is based upon the ThermoSense implementation, which we describe here.

\subsection{ThermoSense Implementation}
\label{subsec:thermosenseimplementation}
The ThermoSense approach combines a \pir, which detects motion, and a \iar which creates a thermal image, to determine occupancy in a sensor fusion. These sensors are fused by leveraging the \pir to determining the $0/>0$ case and the \iar to determine specific occupancy numbers. The specific \iar used subdivides the visible area into an $8\times8$ grid of sections from which temperatures can be derived. This sensor system is attached to the roof on a small embedded controller which is responsible for collecting the thermal data and transmitting it back to another computer for analysis via a low powered wireless networking protocol. 

Machine learning classification, the use of algorithms and training data to generate models that can make predictions on previously unseen data, is a large part of the ThermoSense paper. ThermoSense uses supervised learning algorithms, which require a set of examples with the correct answer.

Supervised classification techniques can be split into two different classes of techniques; numeric and nominal. Numeric techniques provide predictions that are numerical in nature, that is, they return results on a continuous number line. Nominal techniques provide predictions whereby each new data point is predicted to belong to one of a set of predetermined classes, for example, colours of the rainbow.

The training data classification algorithms use is a set of examples that have the corresponding correct answer attached. The set of values that describe each example are known as feature vectors.

Occupants are separated from background radiation through the use of an image subtraction algorithm maintaining per-pixel mean and standard deviation values to update a thermal background map. If no motion is detected, this map is updated using a slow-moving \emwa over a 15 minute time window. If the room remains occupied for a long period, a more complex scaling algorithm is used which considers the coldest points in the room empty, and averages them against the new background, then performs an \emwa with a lower weighting.

This per-pixel average and standard deviation information updated every frame is used to determine several characteristics to be used as feature vectors. The determination of the feature vectors was subject to experimentation, since the differences at each grid element are too susceptible to individual room conditions to be used as feature vectors. Instead, a set of three different features was designed;

\begin{enumerate}
\item \textbf{Number of active pixels}: The total number of pixels that are considered ``active'' in a given frame
\item \textbf{Number of connected components}: If each active pixel is joined with its immediate active neighbours, how many ``islands'' of active pixels (termed connected components in graph theory) exist.
\item \textbf{Size of largest connected component}: The number of active pixels contained within the largest connected component
\end{enumerate}

These feature vectors were compared against three classification approaches; K-Nearest Neighbours, Linear Regression and an Artificial Neural Network. This final classification is subject to a final averaging process over a four minute window, which was determined by experimentation to accurately remove the presence of independent errors from the raw classification data.

In the ThermoSense system, there exists a \pir whose purpose is to determine if there is currently motion in the detected area. This motion detection is averaged over a time window and is used by the ThermoSense system to provide Presence information to the system. Because of this, it is not necessarily a requirement that cases with zero people are provided to the classification algorithms above, as the \pir alone can determine this information. ThermoSense performed experimentation to determine if the classification was more accurate when instances of empty rooms were provided to the classification algorithm vs. not. They found that generally not providing the empty case to the classification algorithm improved accuracy.

\subsection{Sensing}
The \mlx itself is its own computer (see \Fref{fig:exps:blockdia}), containing EEPROM storage, RAM and unspecified code to perform ``digital filtering'' on the $16 \times 4$ array of digital active thermopiles. We are able to communicate with the \mlx through the provided \iic interface, which offers commands to read both the EEPROM, and the sensor's RAM directly. 

The sensor's EEPROM contains configuration values that the interfacing device is required to input into the device's RAM as part of a multi-step initialization sequence, and also contains constants used as part of the raw data to \dc conversion process. The sensor's RAM contains the partially-filtered raw data, which is updated with reference to a clock frequency set between 0.5~Hz to 512~Hz in the initialization process.

The sensor's documentation offers no information regarding reconfiguration of the sensor's internal programming code, nor what code exists on the sensor when purchased. As such, we refer to the sensor's dataset~\cite{MLXDatasheet} and use only the documented commands to interface with the sensor.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{../diagrams/mlx-block-diagram.pdf}
\caption{MLX90620 block diagram (adapted from datasheet~\cite{MLXDatasheet})}
\label{fig:exps:blockdia}
\end{figure}

\subsection{Pre-Processing}

On the Arduino, the \tarl C++ Driver is written as one monolithic Arduino program, termed \texttt{mlx90620\_driver.ino}. This program's purpose is to take simple commands over serial to configure the \mlx and to report back the current temperature values and \pir motion information at either a pre-set interval, or when requested.

To calculate the final temperature values that the \mlx offers, a complex initialization and computational process must be followed, which is specified in the sensor's datasheet~\cite{MLXDatasheet}. This process involves initializing the sensor with values attained from the on-board EEPROM, then retrieving a variety of normalization and adjustment values, along with the raw sensor data, to compute the final temperature result.

The basic algorithm to perform this normalization was based upon the provided datasheet~\cite{MLXDatasheet}, as well as code by users ``maxbot'', ``IIBaboomba'', ``nseidle'' and others on the Arduino Forums~\cite{ArduinoForum} and was modified to operate with the newer \ard ``Wire'' \iic libraries released since the authors' original posts. To ensure the driver can be adapted and extended in the future, the code was also restructured and rewritten to be both more readable, to introduce a set of features to make the management of the sensor data easier for the user, and for the information to be more human readable.

The first of the features introduced was the human-readable format for serial transmission. This allows easy debugging of the sensor with only a rudimentary serial console. When the \ard is powered up, an initialization sequence is output (\Fref{fig:code:initseq}). This specifies several things that are useful to the user; the attached sensor (``DRIVER''), the build of the software (``BUILD'') and the refresh rate of the sensor (``IRHZ''). Several different headers, such as ``ACTIVE'' and ``INIT'' specify the current millisecond time of the processor, thus indicating how long the execution of the initialization process took (33 milliseconds).

Once booted, the user is able to send several one-character commands to the sensor to configure operation. Depending on the input sensor configuration, IR data may be periodically output, or otherwise manually triggered. This IR data is produced in the packet format described in \Fref{fig:code:initseq}.

\begin{figure}
 \centering
\input{../diagrams/init-seq}
\caption{Annotated Arduino initialization sequence and thermal packet serial output}
\label{fig:code:initseq}
\end{figure}

\subsection{Analysis / Classification}

On the Analysis Tier, \tarl's set of Python libraries and accompanying capture and analysis scripts were developed to interface with the Arduino, parse and interpret its data, and to provide data logging and visualization capabilities. \tarl's Python portion provides 4 main feature sets across 3 files; the \texttt{Manager} series of classes, the \texttt{Visualizer} class, the \texttt{Features} class and the \texttt{pxdisplay} module.

\subsubsection*{\texttt{Manager} classes}
The Manager series of classes are the direct interface between \tarl's C++ Arduino driver and \tarl's Python components. They implement a multi-threaded serial data collection and parsing system which converts the raw serial output of the connected Arduino into a series of Python data structures that represent the collected temperature and motion data of each captured frame. Several different versions of the \texttt{Manager} class exist to perform slightly different functions. When initializing these classes the sample rate of the \mlx can be configured, and it will be sent through to the Arduino for updating.

\texttt{BaseManager} is responsible for the implementation of the core serial parsing functions. It also provides a threaded interface through which the \mlx's continuous stream of data can be subscribed to by other threads. The primary API, the \texttt{subscribe\_} series of functions, return a thread-safe queue structure, through which thermal packets can be received by various other threads when they become available.

\texttt{Manager}, the primary class, provides access the \mlx's data at configurable intervals. When initializing this class, you may specific 0.5, 1, 2, 4 or 8~Hz, and the class will configure the Arduino to both set the \mlx to this sample rate, and to automatically write this data to the serial buffer at the same rate. This serial interface is multi-threaded, as at higher serial baud rates if data is not polled continuously the internal serial buffer fills and data is discarded. By ensuring this process cannot be blocked by other parts of the running program this problem is mostly eliminated. 

\texttt{OnDemandManager} operates in a similar way to \texttt{Manager}, however it uses a polling model instead of the periodic model of the other classes. Scripts may request thermal/motion data from the class at any interval, and \texttt{OnDemandManager} will poll the Arduino for information and block until this information is parsed and returned.

Finally, \texttt{ManagerPlaybackEmulator} is a simple class which can take a previously created thermal recording from a file, and emulate the \texttt{Manager} class by providing access to thread-safe queues which return this data at the specified Hz rate. This class can be used as a means to playback thermal recordings with the same visualization functions.

\subsubsection*{\texttt{pxdisplay} functions}

The \texttt{pxdisplay} module is a set of functions that utilize the \texttt{pygame} library to create a simple live-updating window containing a thermal map representation of the thermal data. One can generate any number of \texttt{pxdisplay} objects, which leverage the \texttt{multithreading} library and \texttt{multithreading.Queue} to allow thermal data to be sent to the display.

The class also provides a set of functions to set a ``hotest'' and ``coldest'' temperature and have RGB colours assigned from red to green to blue for each temperature value that falls between those two extremes.

\subsubsection*{\texttt{Visualizer} class}
The \texttt{Visualizer} class is the natural compliment to the \texttt{Manager} series of classes. The functions contained within can be provided with a Queue object (generated by a \texttt{Manager} class) and can perform a variety of visualization and storage functions.

From the recording side, the \texttt{Visualizer} class can ``record'' a thermal capture by saving the motion and thermal information to a simple \texttt{.tcap} file, which stores the sample rate, timings, thermal and motion data from a capture in a simple, plain-text format. The class can also read these files back into the data structures \texttt{Visualizer} uses internally to store data. If \texttt{Visualizer} is running on a Raspberry Pi, it can also leverage the \texttt{picamera} library and the \texttt{OnDemandManager} class to synchronously capture both visual and thermal data for the purposes of ground truth verification.

From the visualization side, \texttt{Visualizer} can leverage the \texttt{pxdisplay} module to create thermal maps that can update in real-time based on the thermal data provided by a \texttt{Manager} class. The class can also generate both images and movie files from thermal recordings using the \texttt{PIL} and \texttt{ffmpeg} libraries.

\subsubsection*{\texttt{Features} class}
As discussed in \Fref{subsec:thermosenseimplementation}, ThermoSense~\cite{beltran2013thermosense} demonstrated the separation of ``background'' information from ``active'' pixels, and from that information, the extraction of the features necessary for a classifier to correctly determine the number of people in an $8\times8$ thermal image.

In accordance with the pseudo-code outlined in the ThermoSense paper and our description of the implementation, the algorithm described in \Fref{lst:exps:featcode} was created to extract the three features identified by ThermoSense; number of active pixels, number of connected components and size of largest connected components.

Given the scope restriction to a minimum viable implementation, the portion of the ThermoSense code dealing with scaling the thermal background for rooms without motion was not implemented. For connected component determination, we leveraged the \texttt{networkx} graph library.

The output of feature information is the extent to which the \texttt{Features} class is involved in machine learning classification. The code used to perform the actual classification step is discussed in \Fref{chap:evaluation}.

\begin{listing}
\centering
\input{../diagrams/feature-extraction}
\caption{Annotated and abbreviated image subtraction and feature extraction code from the Thermal Array Library}
\label{lst:exps:featcode}
\end{listing}

\section{Summary}
We believe that the hardware and software architecture presented here lays a solid foundation on which experimental data can be collected. The hardware architecture, as discussed, as been specifically selected to ensure that there is a transition path from the current USB Serial Pre-Processing/Analysis connection to one which does this wirelessly. The software library, TArL, has been written to be robust and general, so that its functionality is both useful in the current situation, and also for future experiments with this and other prototypes.
 
 \ifcsdef{mainfile}{}{\bibliography{../references/primary}}
\end{document}
